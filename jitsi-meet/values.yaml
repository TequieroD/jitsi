# Default values for jitsi-meet.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

global:
  podLabels: {}
  podAnnotations: {}

  xmpp:
    domain: meet.jitsi
    authDomain:
    mucDomain:
    internalMucDomain:
    guestDomain:

  secretEnvs: 
    JIBRI_RECORDER_PASSWORD: 55053500c942d95cfa4687ec5fd463b8
    JIBRI_XMPP_PASSWORD: 26244b827895fb68e2e4cc91c7965caa
    JICOFO_AUTH_PASSWORD: 1ff0db6ac65d5d70c34da21e8ccc468f
    JIGASI_XMPP_PASSWORD: 73956a0d757eca517b59b4cfb4c83acb
    JVB_AUTH_PASSWORD: 567363f4e762aa79f9980618dd48f15a
    JVB_STUN_SERVERS: meet-jit-si-turnrelay.jitsi.net:443

  # Shard configs. To add new shard just duplicate this `shard-0` block and rename it to shard-1, shard-2,...
  shards:
    shard-0:
      # JVB specific shard configs
      xmppServer: # Overrides XMPP_SERVER for jvb on this shard
      jvbBasePort: 30000 # Base nodeport for jvb on this shard
      jvbWebsocketBasePorts: # Base nodeport to expose colibri websocket
        http:
        # admin:

      # Prosody specific shard configs
      prosodyNodePorts: # Assign nodeport to expose prosody
        bosh-insecure:
        xmpp-c2s:
        xmpp-component:
        # bosh-secure:
        # xmpp-s2s:

    #shard-1:
    #  # JVB specific shard configs
    #  xmppServer: # Overrides XMPP_SERVER for jvb on this shard
    #  jvbBasePort: 31000 # Base nodeport for jvb on this shard
    #  jvbWebsocketBasePorts: # Base nodeport to expose colibri websocket
    #    http:
    #     # admin:

    #   # Prosody specific shard configs
    #  prosodyNodePorts: # Assign nodeport to expose prosody
    #    bosh-insecure:
    #    xmpp-c2s:
    #    xmpp-component:
    #     # bosh-secure:
    #     # xmpp-s2s:

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

enableAuth: false
enableGuests: true
JVB_WS_DOMAIN: meet.dennychen.tw
publicURL: "https://jitsi.dennychen.tw"

ENABLE_AUTH: 0
ENABLE_GUESTS: 1
ENABLE_COLIBRI_WEBSOCKET: 1
GLOBAL_CONFIG: statistics = "internal";\nstatistics_interval = 15;
GLOBAL_MODULES: prometheus,measure_stanza_counts,measure_client_presence
XMPP_MUC_MODULES: muc_meeting_id,muc_domain_mapper

JIBRI_BREWERY_MUC: jibribrewery
JIBRI_RECORDER_USER: recorder
JIBRI_XMPP_USER: jibri

JICOFO_AUTH_USER: focus

JIGASI_BREWERY_MUC: jigasibrewery
JIGASI_XMPP_USER: jigasi

JVB_AUTH_USER: jvb
JVB_BREWERY_MUC: jvbbrewery
JVB_ENABLE_APIS: colibri,rest

tz: Europe/Amsterdam

# Same as above but for storing secrets
secretEnvs: 
  JIBRI_RECORDER_PASSWORD: 55053500c942d95cfa4687ec5fd463b8
  JIBRI_XMPP_PASSWORD: 26244b827895fb68e2e4cc91c7965caa
  JICOFO_AUTH_PASSWORD: 1ff0db6ac65d5d70c34da21e8ccc468f
  JIGASI_XMPP_PASSWORD: 73956a0d757eca517b59b4cfb4c83acb
  JVB_AUTH_PASSWORD: 567363f4e762aa79f9980618dd48f15a
  JVB_STUN_SERVERS: meet-jit-si-turnrelay.jitsi.net:443

  # Any env contains secret should be placed here. Check docker repo for more env: https://github.com/jitsi/docker-jitsi-meet
  # JWT_APP_SECRET: my_jitsi_app_secret
  
image:
  pullPolicy: IfNotPresent

web:
  replicaCount: 1
  image:
    repository: dennychen/jitsi-web

  extraEnvs: {}
  service:
    type: ClusterIP
    port: 80
    externalIPs: []

  ingress:
    enabled: false
    # ingressClassName: "nginx-ingress-0"
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
    - host: jitsi.local
      paths: ['/']
    tls: []
    #  - secretName: jitsi-web-certificate
    #    hosts:
    #      - jitsi.local

  # Useful for ingresses that don't support http-to-https redirect by themself, (namely: GKE),
  httpRedirect: false

  # When tls-termination by the ingress is not wanted, enable this and set web.service.type=Loadbalancer
  httpsEnabled: false

  ## Resolver IP for nginx.
  ## Set this to ClusterIP of your `kube-dns` service
  ## when using websockets and discovering JVB's address
  ## via k8s services.
  # resolverIP: 10.43.0.10

  livenessProbe:
    httpGet:
      path: /
      port: 80
  readinessProbe:
    httpGet:
      path: /
      port: 80

  podLabels: {}
  podAnnotations: {}
  podSecurityContext: {}
    # fsGroup: 2000

  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  nodeSelector: {}

  tolerations: []

  affinity: {}

jicofo:
  replicaCount: 1
  image:
    repository: jitsi/jicofo

  xmpp:
    user: focus
    password:
    componentSecret:

  livenessProbe:
    tcpSocket:
      port: 8888
  readinessProbe:
    tcpSocket:
      port: 8888

  podLabels: {}
  podAnnotations: {}
  podSecurityContext: {}
  securityContext: {}
  resources: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}
  extraEnvs: {}

jvb:
  enabled: true

  replicaCount: 2
  image:
    repository: jitsi/jvb

  xmpp:
    user: jvb
    password:

  stunServers: 'meet-jit-si-turnrelay.jitsi.net:443'
  useHostPort: false
  UDPPort: 30000
  service:
    enabled: true
    port: 80
    type: NodePort
    annotations: {}

  breweryMuc: jvbbrewery

  livenessProbe:
    httpGet:
      path: /about/health
      port: 8080
  readinessProbe:
    httpGet:
      path: /about/health
      port: 8080

  # Expose directly udp port as NodePort.
  #udp:
  #  service:
  #    enabled: true
  #    annotations: {}

  # Expose websocket
  #websocket:
  #  service:
  #    enabled: true
  #    type: ClusterIP
  #    annotations: {}
  #    ports:
  #      http: 9090
  #      # admin: 8080

  podLabels: {}
  podAnnotations: {}
  podSecurityContext: {}
  securityContext: {}
  resources: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}
  extraEnvs: {}

  # Time to wait for JVB to gracefully stop. It depends on your room duration.
  terminationGracePeriodSeconds: 3600
  
  # Expose directly udp port as NodePort.
  udp:
    service:
      enabled: true
      annotations: {}

  websockets:
    ## Set to 'true' to enable Colibri WebSocket support in JVB:
    service:
      enabled: true
      type: ClusterIP
      ports:
        http: 9090
      annotations: {}
    ## Uncomment this to set JVB server ID manually,
    ## Or use one of pre-defined values:
    ## * "podIP" will fetch JVB pod's IP address from K8s metadata;
    ## * "service" will use JVB service name generated by Helm.
    ##
    ## Don't forget to set `web.resolverIP` to your cluster's
    ## DNS service IP when setting this to "service"!
    ##
    ## (default is "podIP")
    # serverID: podIP

    # Enable this ingress to auto expose colibri websocket and load balance between jvbs
    ingress:
      enabled: false
      className: ""
      annotations: {}
        # kubernetes.io/ingress.class: nginx
        # kubernetes.io/tls-acme: "true"
      hosts:
        - ws.meet.example.com
      tls: []
      #  - secretName: chart-example-tls
      #    hosts:
      #      - ws.meet.example.com

  metrics:
    enabled: false
    prometheusAnnotations: false
    image:
      repository: docker.io/systemli/prometheus-jitsi-meet-exporter
      tag: 1.1.9
      pullPolicy: IfNotPresent
    serviceMonitor:
      enabled: true
      selector:
        release: prometheus-operator
      interval: 10s
      # honorLabels: false
    resources:
      requests:
        cpu: 10m
        memory: 16Mi
      limits:
        cpu: 20m
        memory: 32Mi
  
  resources: 
    requests:
      cpu: "200m"
      memory: "200Mi"
    limits:
      cpu: "1000m"
      memory: "1000Mi"

  # JVB autoscaling config. Checkout README.md for more detail on how each JVB's NodePort is calculated
  autoscaling:
    enabled: true
    minReplicas: 1
    maxReplicas: 3
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  nodeSelector: {}

  tolerations: []

  affinity: {}

  # Time to wait for JVB to gracefully stop. It depends on your room duration.
  terminationGracePeriodSeconds: 3600

  allowedEnv:
    - ENABLE_COLIBRI_WEBSOCKET
    - ENABLE_OCTO
    - JVB_AUTH_USER
    - JVB_AUTH_PASSWORD
    - JVB_BREWERY_MUC
    - JVB_STUN_SERVERS
    - JVB_ENABLE_APIS
    - JVB_WS_DOMAIN
    - PUBLIC_URL
    - JVB_OCTO_BIND_ADDRESS
    - JVB_OCTO_PUBLIC_ADDRESS
    - JVB_OCTO_BIND_PORT
    - JVB_OCTO_REGION
    - TZ

  # Enable prometheus exporter sidecar for JVBs
  monitoring:
    enabled: false
    image:
      repository: systemli/prometheus-jitsi-meet-exporter
      pullPolicy: IfNotPresent
      tag: "1.1.6"
    resources: {}
      # requests:
      #   cpu: "100m"
      #   memory: "100Mi"
      # limits:
      #   cpu: "100m"
      #   memory: "100Mi"

octo:
  enabled: false


jibri:
  ## Enabling Jibri will allow users to record
  ## and/or stream their meetings (e.g. to YouTube).
  enabled: false

  ## Enable persistent storage for local recordings.
  ## If disabled, jibri pod will use a transient
  ## emptyDir-backed storage instead.
  persistence:
    enabled: false
    size: 4Gi
    ## Set this to existing PVC name if you have one.
    existingClaim:
    storageClassName:

  shm:
    ## Set to true to enable "/dev/shm" mount.
    ## May be required by built-in Chromium.
    enabled: false
    ## If "true", will use host's shared memory dir,
    ## and if "false" â€” an emptyDir mount.
    # useHost: false
    # size: 256Mi

  image:
    repository: jitsi/jibri

  breweryMuc: jibribrewery
  timeout: 90

  ## jibri XMPP user credentials:
  xmpp:
    user: jibri
    password:

  ## recorder XMPP user credentials:
  recorder:
    user: recorder
    password:

  livenessProbe:
    exec:
      command: ["pgrep", "java"]

  readinessProbe:
    exec:
      command: ["pgrep", "java"]

  extraEnvs: {}

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name:

xmpp:
  domain: meet.jitsi
  authDomain:
  mucDomain:
  internalMucDomain:
  guestDomain:

extraCommonEnvs: {}

prosody:
  enabled: true
  server:
  extraEnvFrom:
  - secretRef:
      name: '{{ include "prosody.fullname" . }}-jicofo'
  - secretRef:
      name: '{{ include "prosody.fullname" . }}-jvb'
  - configMapRef:
      name: '{{ include "prosody.fullname" . }}-common'
        #  extraEnvs:
        #  - name: JVB_AUTH_USER
        #    value: "jvb2"
  ## Uncomment this if you want to use jibri:
  # - secretRef:
  #     name: '{{ include "prosody.fullname" . }}-jibri'
  image:
    repository: jitsi/prosody
    tag: 'stable-7648-4'

# HAproxy specific configurations, used to load balance between shards
haproxy:
  enabled: false
  image: 
    repository: haproxy
    pullPolicy: IfNotPresent
    tag: ""
  imagePullSecrets: []
  podAnnotations: {}

  service:
    type: ClusterIP
    annotations: {}
    port: 80
    # nodePort: 32080

  # Expose this as your web domain
  ingress:
    enabled: false
    className: ""
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  resources: {}
    # limits:
    #   memory: 300Mi
    #   cpu: 400m
    # requests:
    #   memory: 300Mi
    #   cpu: 400m
  nodeSelector: {}
  tolerations: []
  affinity: {}
